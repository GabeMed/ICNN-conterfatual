"""
Train ICNN on DC Optimal Power Flow data.

This example demonstrates training a simplified FICNN for regression on DCOPF data:
- Input (X): Demand vectors (concatenated P and Q for each bus)
- Output (Y): Optimal objective values (scalar)

The FICNN learns to approximate the convex function mapping demand to optimal cost.
"""

using Pkg
Pkg.activate(".")

include("../src/ICNN.jl")
using .ICNN

using Random
using Statistics
using Printf

println("=" ^ 70)
println("Training ICNN on DC Optimal Power Flow Data")
println("=" ^ 70)

# ============================================================================
# 1. Configuration
# ============================================================================

# Data file path (generated by src/data/Generate_DCOPF.jl)
# You need to first run Generate_DCOPF.jl to create this file
data_file = "test_systems/data_pglib_opf_case118_ieee.bson"

# Model hyperparameters
hidden_sizes = [200, 200]  # Two hidden layers with 200 units each
learning_rate = 0.001f0
batch_size = 32
epochs = 50

# Data preprocessing
normalize_method = :standardize  # Options: :standardize, :minmax, :none
train_ratio = 0.8

# Training options
is_convex = true  # Enforce convexity constraints
save_dir = "./tmp/dcopf_experiment"
collect_metrics = true

println("\n📋 Configuration:")
println("   Data file: $data_file")
println("   Hidden layers: $hidden_sizes")
println("   Learning rate: $learning_rate")
println("   Batch size: $batch_size")
println("   Epochs: $epochs")
println("   Normalization: $normalize_method")
println("   Train/Test split: $(train_ratio)/$(1-train_ratio)")
println("   Convexity constraint: $is_convex")

# ============================================================================
# 2. Load and Prepare Data
# ============================================================================

println("\n" * "=" ^ 70)
println("Loading and Preparing Data")
println("=" ^ 70)

if !isfile(data_file)
    error("""
    Data file not found: $data_file

    Please first generate the data by running:
        julia src/data/Generate_DCOPF.jl

    This will create the BSON file with DCOPF problem instances.
    """)
end

# Load and prepare dataset
dataset = prepare_dcopf_dataset(
    data_file;
    train_ratio=train_ratio,
    normalize_method=normalize_method,
    shuffle=true,
    seed=42
)

# Extract dataset components
X_train = dataset.X_train
Y_train = dataset.Y_train
X_test = dataset.X_test
Y_test = dataset.Y_test
n_features = dataset.n_features

println("\n✅ Data loaded successfully!")
println("   Features dimension: $n_features")
println("   Training samples: $(size(X_train, 1))")
println("   Test samples: $(size(X_test, 1))")

# ============================================================================
# 3. Create Model
# ============================================================================

println("\n" * "=" ^ 70)
println("Creating FICNN Model")
println("=" ^ 70)

model = FICNN(n_features, 1; hidden_sizes=hidden_sizes)

println("\n✅ Model created!")
println("   Architecture:")
println("      Input: $n_features features")
for (i, size) in enumerate(hidden_sizes)
    println("      Hidden $i: $size units (ReLU)")
end
println("      Output: 1 value (linear)")
println("\n   Trainable parameters:")
println("      Input layer: $(length(model.input_layer.weight)) weights + $(length(model.input_layer.bias)) biases")
for (i, layer) in enumerate(model.hidden_layers)
    n_params = length(layer.weight)
    println("      Hidden $i: $n_params weights (≥ 0 for convexity)")
end

# ============================================================================
# 4. Train Model
# ============================================================================

println("\n" * "=" ^ 70)
println("Training Model")
println("=" ^ 70)

Random.seed!(42)

model = train!(
    model, X_train, Y_train, epochs;
    learning_rate=learning_rate,
    batch_size=batch_size,
    save_dir=save_dir,
    is_convex=is_convex,
    X_test=X_test,
    y_test=Y_test,
    collect_metrics=collect_metrics
)

println("\n✅ Training completed!")

# ============================================================================
# 5. Evaluate Model
# ============================================================================

println("\n" * "=" ^ 70)
println("Final Evaluation")
println("=" ^ 70)

# Make predictions
y_pred_train = predict(model, X_train)
y_pred_test = predict(model, X_test)

# Calculate metrics
train_mse = mean((y_pred_train .- Y_train) .^ 2)
train_rmse = sqrt(train_mse)
train_mae = mean(abs.(y_pred_train .- Y_train))

test_mse = mean((y_pred_test .- Y_test) .^ 2)
test_rmse = sqrt(test_mse)
test_mae = mean(abs.(y_pred_test .- Y_test))

println("\n📊 Training Set:")
@printf("   MSE:  %.6e\n", train_mse)
@printf("   RMSE: %.6e\n", train_rmse)
@printf("   MAE:  %.6e\n", train_mae)

println("\n📊 Test Set:")
@printf("   MSE:  %.6e\n", test_mse)
@printf("   RMSE: %.6e\n", test_rmse)
@printf("   MAE:  %.6e\n", test_mae)

# Denormalize predictions for interpretation
y_pred_test_denorm = denormalize_output(y_pred_test, dataset.scaler_Y)
y_test_denorm = denormalize_output(Y_test, dataset.scaler_Y)

println("\n📈 Predictions (denormalized, original scale):")
println("   First 10 predictions vs actual:")
for i in 1:min(10, length(y_test_denorm))
    @printf("      Sample %2d: Pred = %.2f, True = %.2f, Error = %.2f\n",
            i, y_pred_test_denorm[i], y_test_denorm[i],
            abs(y_pred_test_denorm[i] - y_test_denorm[i]))
end

# Check convexity constraint
println("\n🔧 Convexity Check:")
for (i, layer) in enumerate(model.hidden_layers)
    w = layer.weight
    n_negative = sum(w .< -1e-6)
    if n_negative == 0
        println("   ✅ Hidden layer $i: All weights ≥ 0 (convexity satisfied)")
    else
        println("   ⚠️  Hidden layer $i: $n_negative negative weights detected!")
    end
    @printf("      Range: [%.6f, %.6f]\n", minimum(w), maximum(w))
end

# ============================================================================
# 6. Save Results
# ============================================================================

println("\n" * "=" ^ 70)
println("Saving Results")
println("=" ^ 70)

println("\n📁 Saved files:")
println("   Best model: $(joinpath(save_dir, "best_model.bson"))")
println("   Final model: $(joinpath(save_dir, "final_model.bson"))")
println("   Training log: $(joinpath(save_dir, "training_log.csv"))")
if collect_metrics
    println("   Metrics: $(joinpath(save_dir, "metrics_julia.json"))")
end

println("\n" * "=" ^ 70)
println("✅ All done!")
println("=" ^ 70)
